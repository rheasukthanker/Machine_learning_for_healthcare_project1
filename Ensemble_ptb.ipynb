{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "df_1 = pd.read_csv(\"ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "Masked (Masking)             (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "BiRNN1 (Bidirectional)       (None, 187, 128)          33792     \n",
      "_________________________________________________________________\n",
      "BiRNN2 (Bidirectional)       (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 339,186\n",
      "Trainable params: 339,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_OUTPUT_UNITS = [64, 128]\n",
    "def get_model():\n",
    "    inp = Input(shape=(187, 1))\n",
    "    current_layer = keras.layers.Masking(mask_value=0., input_shape=(187, 1), name='Masked')(inp)\n",
    "    for i, size in enumerate(RNN_OUTPUT_UNITS):\n",
    "        notLast = i + 1 < len(RNN_OUTPUT_UNITS)\n",
    "        layer = keras.layers.LSTM(size, return_sequences=notLast, dropout=0.2, name = 'LSTM' + str(i+1))\n",
    "        current_layer = keras.layers.Bidirectional(layer, name = 'BiRNN' + str(i+1))(current_layer)\n",
    "    current_layer = keras.layers.Dense(128, name='Dense1', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(64, name='Dense2', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(16, name='Dense3', activation='relu')(current_layer)\n",
    "    logits = keras.layers.Dense(2, name='Output', activation='softmax')(current_layer)\n",
    "    model = models.Model(inputs=inp, outputs=logits)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"baseline_bidir_lstm_ptb.h5\"\n",
    "model.load_weights(file_path)\n",
    "pred_test_bidir_logits= model.predict(X_test)\n",
    "pred_test_bidir= np.argmax(pred_test_bidir_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_sparse=[]\n",
    "for x in Y_test:\n",
    "    if x==0:\n",
    "        Y_test_sparse.append([1,0])\n",
    "    else:\n",
    "        Y_test_sparse.append([0,1])\n",
    "Y_test_sparse=np.array(Y_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidir AUROC 0.904076875399143\n",
      "Bidir AUPRC 0.8668302012199416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Bidir AUROC\",roc_auc_score(Y_test_sparse,pred_test_bidir_logits))\n",
    "print(\"Bidir AUPRC\",sklearn.metrics.average_precision_score(Y_test_sparse,pred_test_bidir_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "Masked (Masking)             (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "rnn1 (SimpleRNN)             (None, 187, 64)           4224      \n",
      "_________________________________________________________________\n",
      "rnn2 (SimpleRNN)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 38,258\n",
      "Trainable params: 38,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_OUTPUT_UNITS = [64, 128]\n",
    "import keras\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def get_model():\n",
    "    inp = Input(shape=(187, 1))\n",
    "    current_layer = keras.layers.Masking(mask_value=0., input_shape=(187, 1), name='Masked')(inp)\n",
    "    for i, size in enumerate(RNN_OUTPUT_UNITS):\n",
    "        notLast = i + 1 < len(RNN_OUTPUT_UNITS)\n",
    "        current_layer = keras.layers.SimpleRNN(size, return_sequences=notLast, dropout=0.2, name = 'rnn' + str(i+1))(current_layer)\n",
    "\n",
    "    current_layer = keras.layers.Dense(64, name='Dense1', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(16, name='Dense2', activation='relu')(current_layer)\n",
    "    logits = keras.layers.Dense(2, name='Output', activation='softmax')(current_layer)\n",
    "    model = models.Model(inputs=inp, outputs=logits)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = get_model()\n",
    "file_path = \"rnn_simple_ptb.h5\"\n",
    "model.load_weights(file_path)\n",
    "pred_test_rnn_logits = model.predict(X_test)\n",
    "pred_test_rnn= np.argmax(pred_test_rnn_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN AUROC 0.5948397782322798\n",
      "RNN AUPRC 0.5734974808766539\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN AUROC\",roc_auc_score(Y_test_sparse,pred_test_rnn_logits))\n",
    "print(\"RNN AUPRC\",sklearn.metrics.average_precision_score(Y_test_sparse,pred_test_rnn_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "Masked (Masking)             (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 187, 32)           4352      \n",
      "_________________________________________________________________\n",
      "lstm2 (LSTM)                 (None, 187, 64)           24832     \n",
      "_________________________________________________________________\n",
      "lstm3 (LSTM)                 (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 137,330\n",
      "Trainable params: 137,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_OUTPUT_UNITS = [32,64, 128]\n",
    "import keras\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def get_model():\n",
    "    inp = Input(shape=(187, 1))\n",
    "    current_layer = keras.layers.Masking(mask_value=0., input_shape=(187, 1), name='Masked')(inp)\n",
    "    for i, size in enumerate(RNN_OUTPUT_UNITS):\n",
    "        notLast = i + 1 < len(RNN_OUTPUT_UNITS)\n",
    "        current_layer = keras.layers.LSTM(size, return_sequences=notLast, dropout=0.2, name = 'lstm' + str(i+1))(current_layer)\n",
    "\n",
    "    current_layer = keras.layers.Dense(64, name='Dense1', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(16, name='Dense2', activation='relu')(current_layer)\n",
    "    logits = keras.layers.Dense(2, name='Output', activation='softmax')(current_layer)\n",
    "    model = models.Model(inputs=inp, outputs=logits)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"lstm_simple_ptb.h5\"\n",
    "model.load_weights(file_path)\n",
    "pred_test_lstm_logits= model.predict(X_test)\n",
    "pred_test_lstm= np.argmax(pred_test_lstm_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM AUROC 0.7568740818973982\n",
      "LSTM AUPRC 0.6963438696063017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"LSTM AUROC\",roc_auc_score(Y_test_sparse,pred_test_lstm_logits))\n",
    "print(\"LSTM AUPRC\",sklearn.metrics.average_precision_score(Y_test_sparse,pred_test_lstm_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "Masked (Masking)             (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "GRU1 (GRU)                   (None, 187, 64)           12672     \n",
      "_________________________________________________________________\n",
      "GRU2 (GRU)                   (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 96,114\n",
      "Trainable params: 96,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_OUTPUT_UNITS = [64, 128]\n",
    "import keras\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def get_model():\n",
    "    inp = Input(shape=(187, 1))\n",
    "    current_layer = keras.layers.Masking(mask_value=0., input_shape=(187, 1), name='Masked')(inp)\n",
    "    for i, size in enumerate(RNN_OUTPUT_UNITS):\n",
    "        notLast = i + 1 < len(RNN_OUTPUT_UNITS)\n",
    "        current_layer = keras.layers.GRU(size, return_sequences=notLast, dropout=0.2, name = 'GRU' + str(i+1))(current_layer)\n",
    "\n",
    "    current_layer = keras.layers.Dense(64, name='Dense1', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(16, name='Dense2', activation='relu')(current_layer)\n",
    "    logits = keras.layers.Dense(2, name='Output', activation='softmax')(current_layer)\n",
    "    model = models.Model(inputs=inp, outputs=logits)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"gru_simple_ptb.h5\"\n",
    "model.load_weights(file_path)\n",
    "pred_test_gru_logits= model.predict(X_test)\n",
    "pred_test_gru= np.argmax(pred_test_gru_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU AUROC 0.8459945734182173\n",
      "GRU AUPRC 0.8256475867656561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"GRU AUROC\",roc_auc_score(Y_test_sparse,pred_test_gru_logits))\n",
    "print(\"GRU AUPRC\",sklearn.metrics.average_precision_score(Y_test_sparse,pred_test_gru_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 187, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 183, 32)      192         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_1 (Conv1D)                (None, 183, 32)      5152        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2_1 (Conv1D)                (None, 183, 32)      5152        Conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ResidualSum_1 (Add)             (None, 183, 32)      0           Conv2_1[0][0]                    \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Act_1 (Activation)              (None, 183, 32)      0           ResidualSum_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_1 (MaxPooling1D)        (None, 90, 32)       0           Act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_2 (Conv1D)                (None, 90, 32)       5152        MaxPool_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2_2 (Conv1D)                (None, 90, 32)       5152        Conv1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ResidualSum_2 (Add)             (None, 90, 32)       0           Conv2_2[0][0]                    \n",
      "                                                                 MaxPool_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Act_2 (Activation)              (None, 90, 32)       0           ResidualSum_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_2 (MaxPooling1D)        (None, 43, 32)       0           Act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_3 (Conv1D)                (None, 43, 32)       5152        MaxPool_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2_3 (Conv1D)                (None, 43, 32)       5152        Conv1_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ResidualSum_3 (Add)             (None, 43, 32)       0           Conv2_3[0][0]                    \n",
      "                                                                 MaxPool_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Act_3 (Activation)              (None, 43, 32)       0           ResidualSum_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_3 (MaxPooling1D)        (None, 20, 32)       0           Act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_4 (Conv1D)                (None, 20, 32)       5152        MaxPool_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2_4 (Conv1D)                (None, 20, 32)       5152        Conv1_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ResidualSum_4 (Add)             (None, 20, 32)       0           Conv2_4[0][0]                    \n",
      "                                                                 MaxPool_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Act_4 (Activation)              (None, 20, 32)       0           ResidualSum_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_4 (MaxPooling1D)        (None, 8, 32)        0           Act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_5 (Conv1D)                (None, 8, 32)        5152        MaxPool_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2_5 (Conv1D)                (None, 8, 32)        5152        Conv1_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ResidualSum_5 (Add)             (None, 8, 32)        0           Conv2_5[0][0]                    \n",
      "                                                                 MaxPool_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Act_5 (Activation)              (None, 8, 32)        0           ResidualSum_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_5 (MaxPooling1D)        (None, 2, 32)        0           Act_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           MaxPool_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC1 (Dense)                     (None, 64)           4160        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC2 (Dense)                     (None, 32)           2080        FC1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 2)            66          FC2[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 58,018\n",
      "Trainable params: 58,018\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def conv_unit(unit, input_layer):\n",
    "    s = '_' + str(unit)\n",
    "    layer = Convolution1D(name='Conv1' + s, filters=32, kernel_size=5, strides=1, padding='same', activation='relu')(input_layer)\n",
    "    layer = Convolution1D(name='Conv2' + s, filters=32, kernel_size=5, strides=1, padding='same', activation=None)(layer )\n",
    "    layer = keras.layers.Add(name='ResidualSum' + s)([layer, input_layer])\n",
    "    layer = keras.layers.Activation(\"relu\", name='Act' + s)(layer)\n",
    "    layer = keras.layers.MaxPooling1D(name='MaxPool' + s, pool_size=5, strides=2)(layer)\n",
    "    return layer\n",
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(187, 1))\n",
    "    current_layer = Convolution1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "\n",
    "    for i in range(5):\n",
    "        current_layer = conv_unit(i + 1, current_layer)\n",
    "\n",
    "    current_layer = keras.layers.Flatten()(current_layer)\n",
    "    current_layer = keras.layers.Dense(64, name='FC1', activation='relu')(current_layer)\n",
    "    current_layer = keras.layers.Dense(32, name='FC2', activation='relu')(current_layer)\n",
    "    logits = keras.layers.Dense(2,activation=activations.softmax, name='Output')(current_layer)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=logits)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = get_model()\n",
    "file_path = \"residual_cnn_ptb.h5\"\n",
    "model.load_weights(file_path)\n",
    "pred_test_res_cnn_logits= model.predict(X_test)\n",
    "pred_test_res_cnn= np.argmax(pred_test_res_cnn_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual CNN 0.9970651589692082\n",
      "Residual AUPRC 0.9973457021022538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Residual CNN\",roc_auc_score(Y_test_sparse,pred_test_res_cnn_logits))\n",
    "print(\"Residual AUPRC\",sklearn.metrics.average_precision_score(Y_test_sparse,pred_test_res_cnn_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_votes=np.concatenate([np.reshape(pred_test_res_cnn,[2911,1]),np.reshape(pred_test_bidir,[2911,1]),np.reshape(pred_test_gru,[2911,1]),np.reshape(pred_test_lstm,[2911,1]),np.reshape(pred_test_rnn,[2911,1])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "modes=mode(all_votes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_only=np.array(np.squeeze(modes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.7004557922662094 \n",
      "Test accuracy score : 0.8179319821367228 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, modes_only,average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, modes_only)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_logits_bidir=[]\n",
    "for i in range(0,np.shape(pred_test_bidir)[0]):\n",
    "    true_logits_bidir.append(pred_test_bidir_logits[i,Y_test[i]])\n",
    "true_logits_bidir=np.array(true_logits_bidir)\n",
    "true_logits_rnn=[]\n",
    "for i in range(0,np.shape(pred_test_rnn)[0]):\n",
    "    true_logits_rnn.append(pred_test_rnn_logits[i,Y_test[i]])\n",
    "true_logits_rnn=np.array(true_logits_rnn)\n",
    "true_logits_lstm=[]\n",
    "for i in range(0,np.shape(pred_test_lstm)[0]):\n",
    "    true_logits_lstm.append(pred_test_lstm_logits[i,Y_test[i]])\n",
    "true_logits_lstm=np.array(true_logits_lstm)\n",
    "true_logits_gru=[]\n",
    "for i in range(0,np.shape(pred_test_gru)[0]):\n",
    "    true_logits_gru.append(pred_test_gru_logits[i,Y_test[i]])\n",
    "true_logits_gru=np.array(true_logits_gru)\n",
    "true_logits_res_cnn=[]\n",
    "for i in range(0,np.shape(pred_test_res_cnn)[0]):\n",
    "    true_logits_res_cnn.append(pred_test_res_cnn_logits[i,Y_test[i]])\n",
    "true_logits_res_cnn=np.array(true_logits_res_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_logits=np.concatenate([np.reshape(true_logits_bidir,[2911,1]),\n",
    "                           np.reshape(true_logits_rnn,[2911,1]),\n",
    "                           np.reshape(true_logits_lstm,[2911,1]),\n",
    "                           np.reshape(true_logits_gru,[2911,1]),\n",
    "                           np.reshape(true_logits_res_cnn,[2911,1])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_logits_sum=np.sum(full_logits,axis=1)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rheasukthanker/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(full_logits,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=clf.predict(full_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9786756664835309 \n",
      "Test accuracy score : 0.983167296461697 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, preds,average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, preds)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
